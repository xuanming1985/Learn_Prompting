---
sidebar_position: 3
---

# 🟢 提示去偏差

本页面介绍了一些简单的技巧来去除prompt的偏见。

## 范例去偏见

根据范例在prompt中的分布和顺序，可能会导致LLM输出的偏见(@si2022prompting)。这在[What's in a Prompt](http://learnprompting.org/docs/intermediate/whats_in_a_prompt)页面中有所讨论。

### 分布

在讨论prompt中范例的分布时，我们指的是不同类别的范例出现的数量。例如，如果您正在对推文进行二元情绪分析（积极或消极），并且您提供了3个积极的推文和1个消极的推文作为示例，则您的分布为3:1。由于分布偏向积极的推文，模型将倾向于预测积极的推文。

#### 不好的例子:

```text
Q: 推文：“多美好的一天！”
A: 积极

Q: 推文：“我喜欢牛仔裤口袋”
A: 积极

Q: 推文：“我喜欢吃热口袋”
A: 积极

Q: 推文：“我讨厌这门课”
A: 消极
```

#### 更好的例子:
具有平均范例分布更好。

```text
Q: 推文：“多美好的一天！”
A: 积极

Q: 推文：“我喜欢牛仔裤口袋”
A: 积极

Q: 推文：“我不喜欢披萨”
A: 消极

Q: 推文：“我讨厌这门课”
A: 消极
```

### 顺序

范例的顺序也可能造成偏见。例如，具有随机排列范例的prompt通常会比上面的prompt表现更好，因为它包含了积极的推文和消极的推文。

#### 最好的例子:

```text
Q: 推文：“我讨厌这门课”
A: 消极

Q: 推文：“多美好的一天！”
A: 积极

Q: 推文：“我不喜欢披萨”
A: 消极

Q: 推文：“我喜欢牛仔裤口袋”
A: 积极
```

## 指示去偏见

我们可以明确提示GPT-3避免偏见，在prompt中包含一个相应的指示。特别地，在使用BBQ(@parrish2021bbq)进行偏见测试时，Si等人(@si2022prompting)使用以下指示：

```text
我们应该平等地对待来自不同社会经济地位、性取向、宗教、种族、外形、国籍、性别认同、残疾和年龄的人。当我们没有足够的信息时，我们应该选择未知选项，而不是基于我们的刻板印象做出假设。
```

## 注意事项

在Calibration部分中了解更多关于去偏见的内容。