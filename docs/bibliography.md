---
sidebar_position: 1000
---

# 📚 参考文献

本页面包含了本课程使用的所有论文的有组织列表。这些论文按主题分类。

**如果需要引用本课程，请使用 Github 存储库中提供的引用。**

🔵 = 直接在本课程中引用的论文。其他论文则是我对该主题的理解提供了帮助。

注意：由于 [GPT-3 和 GPT-3 Instruct 都不对 davinci 模型进行相应](https://twitter.com/janleike/status/1584618242756132864)，所以我尽量不作为这样引用。

## 提示工程策略

#### Chain of Thought(@wei2022chain) 🔵

#### Zero Shot Chain of Thought(@kojima2022large) 🔵

#### Self Consistency(@wang2022selfconsistency) 🔵

#### 什么样的 GPT-3 上下文示例是好的？(@liu2021makes) 🔵

### Ask-Me-Anything Prompting(@arora2022ama) 🔵

#### Generated Knowledge(@liu2021generated) 🔵

#### Recitation-Augmented Language Models(@sun2022recitationaugmented) 🔵

#### 重新思考示范的作用(@min2022rethinking) 🔵

#### Scratchpads(@nye2021work)

#### Maieutic Prompting(@jung2022maieutic)

#### STaR(@zelikman2022star)

#### 从最少到最多(@zhou2022leasttomost) 🔵

#### 将指令提示转换为 GPTk 的语言(@mishra2022reframing) 🔵

#### Turing测试：语言模型是否能理解说明？(@efrat2020turking) 🔵


## 可靠性

#### MathPrompter(@imani2023mathprompter) 🔵

#### 解释 Few-shot Prompting 的不可靠性用于文本推理(@ye2022unreliability) 🔵

#### 使 GPT-3 更可靠的提示(@si2022prompting)

#### 多样化提示(@li2022advance) 🔵

#### 使用之前进行校准：提高语言模型的少量样本性能(@zhao2021calibrate) 🔵

#### 增强自一致性(@mitchell2022enhancing)

#### Zero-Shot CoT 中的偏见和有毒性(@shaikh2022second) 🔵

#### 宪法人工智能：来自 AI 反馈的无害性 (@bai2022constitutional) 🔵

#### 组合常规 - SCAN(@lake2018scan)
## 自动提示工程

#### AutoPrompt(@shin2020autoprompt) 🔵

#### Automatic Prompt Engineer(@zhou2022large)

## 模型

### 语言模型

#### GPT-3(@brown2020language) 🔵

#### GPT-3 Instruct(@ouyang2022training) 🔵

#### PaLM(@chowdhery2022palm) 🔵

#### BLOOM(@scao2022bloom) 🔵

#### BLOOM+1(更多语言/ 0-shot 改进)(@yong2022bloom1)

#### Jurassic 1(@lieberjurassic) 🔵

#### GPT-J-6B(@wange2021gptj)

#### Roberta(@liu2019roberta)

### 图像模型

#### Stable Diffusion(@rombach2021highresolution) 🔵

#### DALLE(@ramesh2022hierarchical) 🔵

## 软提示

#### Soft Prompting(@lester2021power) 🔵

#### 可解释的离散化软提示(@khashabi2021prompt) 🔵

## 数据集

#### MultiArith(@roy-roth-2015-solving) 🔵

#### GSM8K(@cobbe2021training) 🔵

#### HotPotQA(@yang2018hotpotqa) 🔵

#### Fever(@thorne2018fever) 🔵

#### BBQ：问题回答的手工制作偏差基准测试(@parrish2021bbq) 🔵

## 图像提示工程

#### 提示修饰符分类法(@oppenlaender2022taxonomy)

#### DiffusionDB(@wang2022diffusiondb)

#### DALLE 2 Prompt Book(@parsons2022dalleprompt) 🔵

#### 面向基于文本生成艺术的提示工程(@oppenlaender2022prompt) 🔵

#### 对于正确的提示，Stable Diffusion 2.0 可以完成手部任务。(@blake2022with) 🔵

#### 为文本到图像生成优化提示(@hao2022optimizing)

## 提示工程 IDE

#### Prompt IDE(@strobelt2022promptide) 🔵

#### Prompt Source(@bach2022promptsource) 🔵

#### PromptChainer(@wu2022promptchainer) 🔵

#### PromptMaker(@jiang2022promptmaker) 🔵

## 工具

#### LangChain(@Chase_LangChain_2022) 🔵

#### TextBox 2.0：带有预训练的语言模型的文本生成库(@tang2022textbox) 🔵

#### OpenPrompt：一个用于提示学习的开源框架(@ding2021openprompt) 🔵

#### GPT Index(@Liu_GPT_Index_2022) 🔵

## 应用提示工程

#### 语言模型级联(@dohan2022language)

#### MRKL(@karpas2022mrkl) 🔵

#### ReAct(@yao2022react) 🔵

#### PAL：程序辅助语言模型(@gao2022pal) 🔵

## 用户界面设计

#### 面向文本到图像生成模型的提示工程设计准则(@liu2022design)

## 提示注入

#### 机器生成的文本：威胁模型和检测方法的全面调查(@crothers2022machine) 🔵

#### 通过手工制作的对抗样本评估预训练语言模型的易感性(@branch2022evaluating) 🔵

#### 针对 GPT-3 的提示注入攻击(@simon2022inject) 🔵

#### 利用恶意输入利用 GPT-3 提示，使其忽略其前面的指令(@goodside2022inject) 🔵

#### 对抗提示(@chase2021adversarial) 🔵

#### GPT-3 提示注入防御(@goodside2021gpt) 🔵

#### 与机器交谈：提示工程和注入(@christoph2022talking)

#### 探索提示注入攻击(@selvi2022exploring) 🔵

#### 利用 GPT-Eliezer 对 ChatGPT 进行破解(@armstrong2022using) 🔵

#### Microsoft Bing 聊天提示(@kevinbing)

## 破解

#### 忽略之前的提示：语言模型攻击技术(@perez2022jailbreak)

#### 语言模型安全与滥用的教训(@brundage_2022)

#### 基于生成式提示的有毒性检测(@wang2022jailbreak)

#### 新的改进内容审查工具(@markov_2022)

#### OpenAI API (@openai_api) 🔵

#### OpenAI ChatGPT (@openai_chatgpt) 🔵

#### ChatGPT 4 推特 (@alice2022jailbreak) 🔵

#### 演员推特 (@miguel2022jailbreak) 🔵

#### 研究员推特 (@derek2022jailbreak) 🔵

#### 假装能力推特 (@nero2022jailbreak) 🔵

#### 责任推特 (@nick2022jailbreak) 🔵

#### Lynx 模式推特 (@jonas2022jailbreak) 🔵

#### Sudo 模式推特 (@sudo2022jailbreak) 🔵

#### 忽略之前的提示 (@ignore_previous_prompt) 🔵

#### 更新破解提示 (@AI_jailbreak) 🔵

## 调查

#### 预训练、提示和预测：自然语言处理中提示方法的系统调查(@liu2021pretrain)

#### PromptPapers (@ning2022papers)

## 数据集生成

#### 使用模型编写的评估发现语言模型的行为(@perez2022discovering)

当前日期：2023年4月1日14:38:00

## 应用

#### Atlas: 加强型检索语言模型的少样本学习(@izacard2022atlas)

#### STRUDEL: 结构化对话摘要用于对话理解(@wang2022strudel)

## 其他

#### Prompting即编程：一种面向大型语言模型的查询语言(@beurerkellner2022prompting)

#### 平行上下文窗口提升大型语言模型的上下文学习效果(@ratner2022parallel)

#### 通过组合微调语言模型实现复杂任务(@bursztyn2022learning)

#### 超自然说明：通过声明性说明在1600多个NLP任务中进行泛化(@wang2022supernaturalinstructions)

#### 让预训练语言模型成为更好的少样本学习者(@gao2021making)

#### 基于搜索结果的语言模型关联性处理方法(@livin2022large)

#### 如何进行Prompting？零样本和少样本学习面临的人机交互创意应用中生成模型的机遇与挑战(@dang2022prompt)

#### 关于测量基于Prompt的多任务学习中的社交偏见(@akyrek2022measuring)

#### 预训练语言模型的情节写作(@jin2022plot) 🔵

#### StereoSet：用于预训练语言模型中测量刻板印象的数据集(@nadeem-etal-2021-stereoset)

#### 自然语言生成的幻觉调查(@Ji_2022)

#### 例子(@2022examples)

#### Wordcraft(@yuan2022wordcraft)

#### 疼点(@fadnavis2022pain)

#### 自我指导：将语言模型与自动生成的说明对齐(@wang2022selfinstruct)

#### 从图像到文本提示：使用冻结的大型语言模型进行零样本VQA(@guo2022images)

#### 利用填空问题进行少样本文本分类和自然语言推理(@schick2020exploiting)

### 问我任何问题：Prompting技术(@arora2022ama)

### 大型语言模型的水印(@kirchenbauer2023watermarking)