---
sidebar_position: 1
---

# 🔴 柔性提示

Prompt调整（@lester2021power）是模型微调（@khashabi2021prompt）的一种替代方法，它冻结模型权重并更新提示的参数。由此产生的提示是“柔性提示”。


import Image from '../assets/prompt_tuning.png';

<div style={{textAlign: 'center'}}>
  <img src={Image} style={{width: "500px"}} />
</div>

<div style={{textAlign: 'center'}}>
Model Tuning vs Prompt Tuning (Lester et al.)
</div>

上图对比了模型微调和Prompt调整。在模型微调中，您微调相同的模型以完成不同的任务。这会给您提供几个不同的模型，但这些模型未必能方便地批量处理输入。

另一方面，Prompt调整允许您在所有任务中使用相同的模型。您只需在推理时添加适当的提示即可，从而更容易地在不同的任务之间进行批次处理。这基本上与常规提示具有相同的优点。此外，针对单个模型跨多个任务训练的柔性提示通常具有相同的标记长度。

## 工作原理

为了理解柔性提示背后的基本逻辑，让我们思考关于如何在给定提示上进行**模型推理**的基本过程：“2+2等于多少？”。

1）它可能被标记为`What, 's, 2, +, 2, ?`。

2）然后，每个标记将转换为一组值的向量。

3）这些向量可以被认为是模型参数。模型可以进一步训练，仅调整这些提示的权重。

请注意，一旦我们开始更新这些权重，标记的向量就不再对应于词汇表中实际的嵌入。

# 结果

Prompt调整在较大的模型中表现更好。较大的模型也需要更少的柔性提示标记。无论如何，多于20个标记并不会带来显著的性能提升。

