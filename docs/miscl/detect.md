---
sidebar_position: 1
--- 

# 🟢 检测AI生成的文本

对于安全研究人员和教育工作者等人来说，检测AI生成的文本是一个很大的问题。像[GPTZero](https://gptzero.me)、[GPT2 detector](https://openai-openai-detector.hf.space)和[双语检测器](https://github.com/Hello-SimpleAI/chatgpt-comparison-detection)这样的工具已经取得了相当大的成功，但是它们仍然会被[欺骗](https://learnprompting.org/docs/miscl/trickery)。

OpenAI和其他研究人员（@bansal2022certified）(@gu2022watermarking)正在致力于将统计数字水印引入到他们的生成文本中，但这也可能被修改大量文本的方法所欺骗。

AI文本检测问题很可能会成为一场军备竞赛，随着新模型和新检测方法的引入。许多公司已经开始构建他们声称非常有效的解决方案，但要证明这一点是很困难的，特别是随着时间的推移模型不断变化。

本文将介绍一些当前用于检测AI生成文本的方法，下一篇文章将讨论一些人们发现的方法来欺骗它们。

## OpenAI文本分类器

[OpenAI文本分类器](https://platform.openai.com/ai-text-classifier)是一个相当好的通用AI文本检测器。通过在大量的AI生成数据和类似质量的人工编写的文本上训练模型，该检测器能够计算任何给定文本被LLM创建的可能性。

它有一些局限性 - 它不接受任何少于1000个单词的提交，文本可以轻松地被编辑以干扰概率计算，并且由于其专业化的训练集，它更难处理儿童或非英语母语者创建的文本。 

它目前仅将人类文本标记为AI生成的文本约9％的时间，并正确识别AI生成的文本约26％的时间。随着模型的增强和范围的扩大，这些数字将会提高，但有可能需要更特定的检测器来充分评估生成文本的真假。

## 水印法

检测AI生成文本的一种方法是在生成文本时引入统计数字水印。这些技术可能使用LLM“白名单”，这是一种确定文本是否由特定AI模型生成的方法。水印的工作原理是在生成单词之前选择一组随机化的“绿色”符号，然后在采样过程中软性地促进选择这些符号的使用。这些加权值对生成的质量影响很小，但可以通过另一个LLM算法检测到。

这是一个有趣的想法，但需要模型的创建者将这个框架实现到他们的LLM中。如果模型没有内置水印，则无法使用此方法。

## DetectGPT

[DetectGPT](https://detectgpt.ericmitchell.ai/)（@mitchell2023detectgpt）方法能够比之前的概念更简单地检测AI生成文本。研究人员发现LLM文本生成倾向于“占据模型对数概率函数的负曲率区域”。因此，可以创建一种基于曲率的系统来确定是否以程序方式生成了一段文本。

它的工作原理是计算源模型从文本生成中思考出的对数概率，并将其与另一个预先训练的通用语言模型的文本进行随机更改进行比较。通过这种方式，DetectGPT能够仅通过概率曲线来确定文本块被生成的可能性！

## 注意

有关探测器和人们如何欺骗它们的更多讨论，请参见[本文](https://learnprompting.org/docs/miscl/trickery)。