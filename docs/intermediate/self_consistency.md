---
sidebar_position: 5
---
# 🟡 自一致性

自一致性（Self-consistency）(@wang2022selfconsistency) 是对于 CoT 的一种追踪，它可以生成多个推理链，取其中最多的答案作为最终答案。

下图是使用 Few-Shot-CoT 范例编写的初始提示。使用这个提示，独立生成多个推理链，从每个链中提取答案，最终答案是通过“边缘化推理路径”来计算得到的。在实践中，这只是取大多数答案的意思。

import SCImage from '@site/docs/assets/self_consistency.png';

<div style={{textAlign: 'center'}}>
  <img src={SCImage} style={{width: "750px"}} />
</div>

<div style={{textAlign: 'center'}}>
自一致性 (Wang et al.)
</div>

## 示例

假设你是一家软件公司，每天会收到数百封电子邮件。你想使用模型将邮件分类为重要或不重要，以便优先处理那些可能对业务产生重大影响的邮件。

以下是一封您可能会收到的电子邮件的示例：

```text
你好，

我发现了一个严重的安全漏洞，虽然难以利用，但仍有可能访问你们所有用户的数据。我附上了一个概念证明，请尽快解决此问题。

谢谢，

唐尼
```

让我们把它放到提示中：

```text
你好，

我发现了一个严重的安全漏洞，虽然难以利用，但仍有可能访问你们所有用户的数据。我附上了一个概念证明，请尽快解决此问题。

谢谢，

唐尼

将上述电子邮件作为与软件公司相关的重要或不重要内容进行分类。我们按步骤思考。
```

现在，我们将使用以上提示来生成多个独立完成/推理链。以下是几个示例：

```text
<!-- highlight-start -->
发件人发现了系统中的一个严重安全漏洞。由于该漏洞可能导致数据泄露，这很重要。我将此电子邮件归类为“重要”。
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
发件人发现了系统中的一个严重安全漏洞，但他们没有提供任何概念证明，而且很难利用。我将此电子邮件归类为“不重要”。
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
发件人很可能是黑客，并且可能已经访问了该系统。由于这可能导致数据泄露，这很重要。我将此电子邮件归类为“重要”。
<!-- highlight-end -->
```

通过生成多个推理链，并取最常出现的答案（`重要`），我们可以从 GPT-3 中获得更一致的正确答案。

## 结果

自一致性已经被证明可以提高算术、常识和符号推理任务的结果。

即使常规 CoT 被发现无效(@ye2022unreliability)，自一致性仍然能够改善结果。

## 备注

Wang 等人讨论了一种更复杂的方法来边缘化推理路径，它处理了每个推理链产生的 LLM 生成的概率。但是，在他们的实验中，他们并未使用此方法，而大多数投票似乎通常具有相同或更好的性能。